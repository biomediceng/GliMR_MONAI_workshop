{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Glioma classification\n",
    "\n",
    "This notebook demonstrates classification of brain tumors with MONAI. To accelerate training, we generate a 2D dataset from a 3D one.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The dataset used here is the Decathlon 3D brain tumor dataset, taking the 2D slice containing the most voxels > 0 (the most label), and then saving the new dataset to disk. We'll download the pre-computed dataset from Google Drive, but the script is available in case you're interested.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rijobro/GliMR_MONAI_workshop/blob/main/2D_Glioma_classification.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment\n",
    "\n",
    "This checks if MONAI is installed, and if not installs it (plus any optional extras that might be needed for this notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel, tqdm]\"\n",
    "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "from functools import partial\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tempfile\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import monai\n",
    "from monai.apps import download_and_extract\n",
    "from monai.data import (\n",
    "    CacheDataset,\n",
    "    DataLoader,\n",
    "    Dataset,\n",
    "    pad_list_data_collate,\n",
    "    TestTimeAugmentation,\n",
    "    decollate_batch,\n",
    ")\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks import eval_mode\n",
    "from monai.networks.nets import UNet\n",
    "import monai.transforms as mt\n",
    "from monai.transforms.utils import allow_missing_keys_mode\n",
    "from monai.utils import first, set_determinism\n",
    "\n",
    "monai.config.print_config()\n",
    "\n",
    "# Set deterministic training for reproducibility\n",
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data directory\n",
    "\n",
    "You can specify a directory with the `MONAI_DATA_DIRECTORY` environment variable.  \n",
    "This allows you to save results and reuse downloads.  \n",
    "If not specified a temporary directory will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else os.path.expanduser(directory)\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Get 2D data\n",
    "\n",
    "We'll download the pre-computed dataset from Google Drive, but the script is available in case you're interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_from_gdrive = False\n",
    "task = \"Task01_BrainTumour\"\n",
    "output_dir = os.path.join(root_dir, task + \"2D\")\n",
    "\n",
    "if download_from_gdrive:\n",
    "    resource = \"https://drive.google.com/file/d/1BB0S2PcY6yUR7TK-AeyCFoh6PyoJiH0E\"\n",
    "    compressed_file = os.path.join(root_dir, task + \"2D.tar\")\n",
    "    md5 = \"a2482cf48b7c72b09b4b647820e61c8e\"\n",
    "    download_and_extract(resource, compressed_file, root_dir, hash_val=md5)\n",
    "else:\n",
    "    %run -i ../utils/2d_slice_creator.py --path {output_dir} --download_path {root_dir} --task {task}\n",
    "    \n",
    "images = sorted(glob(os.path.join(output_dir, \"image\", \"*.nii.gz\")))\n",
    "labels = sorted(glob(os.path.join(output_dir, \"label\", \"*.nii.gz\")))\n",
    "assert len(images) == len(labels)\n",
    "data_dicts = [{\"image\": image, \"label\": label}\n",
    "              for image, label in zip(images, labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data_dicts)\n",
    "num_files = len(data_dicts)\n",
    "num_train_files = round(0.8 * num_files)\n",
    "train_files = data_dicts[:num_train_files]\n",
    "val_files = data_dicts[num_train_files:]\n",
    "print(\"total num files:\", len(data_dicts))\n",
    "print(\"num training files:\", len(train_files))\n",
    "print(\"num validation files:\", len(val_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"image\", \"label\"]\n",
    "train_transforms = mt.Compose(\n",
    "    [\n",
    "        mt.LoadImaged(keys),\n",
    "        mt.Lambdad(\"label\", lambda x: (x > 0).astype(np.float32)),  # make label binary\n",
    "        mt.RandAffined(\n",
    "            keys,\n",
    "            prob=1.0,\n",
    "            spatial_size=(300, 300),\n",
    "            rotate_range=(np.pi / 3, np.pi / 3),\n",
    "            translate_range=(3, 3),\n",
    "            scale_range=((0.8, 1), (0.8, 1)),\n",
    "            padding_mode=\"zeros\",\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        mt.CropForegroundd(keys, source_key=\"image\"),\n",
    "        mt.DivisiblePadd(keys, 16),\n",
    "        mt.ScaleIntensityd(\"image\"),\n",
    "        mt.EnsureTyped(keys),\n",
    "    ]\n",
    ")\n",
    "val_transforms = train_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CacheDataset(\n",
    "    data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=4)\n",
    "train_loader = DataLoader(train_ds, batch_size=10,\n",
    "                          num_workers=10, collate_fn=pad_list_data_collate)\n",
    "val_ds = CacheDataset(\n",
    "    data=val_files, transform=train_transforms, cache_rate=1.0, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size=1,\n",
    "                        num_workers=10, collate_fn=pad_list_data_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def imshows(ims):\n",
    "    nrow = len(ims)\n",
    "    ncol = len(ims[0])\n",
    "    fig, axes = plt.subplots(nrow, ncol, figsize=(\n",
    "        ncol * 3, nrow * 3), facecolor='white')\n",
    "    for i, im_dict in enumerate(ims):\n",
    "        for j, (title, im) in enumerate(im_dict.items()):\n",
    "            if isinstance(im, torch.Tensor):\n",
    "                im = im.detach().cpu().numpy()\n",
    "            im = np.mean(im, axis=0)  # average across channels\n",
    "            if len(ims) == 1:\n",
    "                ax = axes[j]\n",
    "            else:\n",
    "                ax = axes[i, j]\n",
    "            ax.set_title(f\"{title}\\n{im.shape}\")\n",
    "            im_show = ax.imshow(im)\n",
    "            ax.axis(\"off\")\n",
    "            fig.colorbar(im_show, ax=ax)\n",
    "\n",
    "\n",
    "to_imshow = []\n",
    "for file in np.random.choice(train_files, size=5, replace=False):\n",
    "    data = train_transforms(file)\n",
    "    to_imshow.append({\"image\": data[\"image\"], \"label\": data[\"label\"]})\n",
    "imshows(to_imshow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for live plotting whilst running training\n",
    "def plot_range(data, wrapped_generator):\n",
    "    # Get ax, show plot, etc.\n",
    "    plt.ion()\n",
    "    for d in data.values():\n",
    "        ax = d[\"line\"].axes\n",
    "    fig = ax.get_figure()\n",
    "    fig.show()\n",
    "\n",
    "    for i in wrapped_generator:\n",
    "        yield i\n",
    "        # update plots, legend, view\n",
    "        for d in data.values():\n",
    "            d[\"line\"].set_data(d[\"x\"], d[\"y\"])\n",
    "        ax.legend()\n",
    "        ax.relim()\n",
    "        ax.autoscale_view()\n",
    "        fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_trans = mt.Compose([\n",
    "    mt.Activations(sigmoid=True),\n",
    "    mt.AsDiscrete(threshold=0.5),\n",
    "    mt.KeepLargestConnectedComponent(applied_labels=1),\n",
    "])\n",
    "\n",
    "\n",
    "def infer_seg(images, model):\n",
    "    val_outputs = model(images)\n",
    "    return torch.stack([post_trans(i) for i in decollate_batch(val_outputs)])\n",
    "\n",
    "\n",
    "# Create network, loss fn., etc.\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "in_channels = train_ds[0][\"image\"].shape[0]\n",
    "# create UNet, DiceLoss and Adam optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = UNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=in_channels,\n",
    "    out_channels=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)\n",
    "loss_function = DiceLoss(sigmoid=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "best_model_path = \"best_model_2d_glioma_classification.pth\"\n",
    "\n",
    "# Plotting stuff\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10), facecolor=\"white\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Metric\")\n",
    "\n",
    "data = {}\n",
    "for i in [\"train\", \"val dice\"]:\n",
    "    data[i] = {\"x\": [], \"y\": []}\n",
    "    (data[i][\"line\"],) = ax.plot(data[i][\"x\"], data[i][\"y\"], label=i)\n",
    "\n",
    "# start a typical PyTorch training\n",
    "max_epochs = 100\n",
    "val_interval = 1\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "\n",
    "for epoch in plot_range(data, range(max_epochs)):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch_data in train_loader:\n",
    "        inputs, labels = batch_data[\"image\"].to(\n",
    "            device), batch_data[\"label\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(train_loader)\n",
    "    data[\"train\"][\"x\"].append(epoch + 1)\n",
    "    data[\"train\"][\"y\"].append(epoch_loss)\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        with eval_mode(model):\n",
    "            val_outputs = None\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = val_data[\"image\"].to(\n",
    "                    device), val_data[\"label\"].to(device)\n",
    "                val_outputs = infer_seg(val_images, model)\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "            # aggregate the final mean dice result\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            # reset the status for next validation round\n",
    "            dice_metric.reset()\n",
    "\n",
    "            data[\"val dice\"][\"x\"].append(epoch + 1)\n",
    "            data[\"val dice\"][\"y\"].append(metric)\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "print(\n",
    "    f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(best_model_path))\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check segmentations\n",
    "\n",
    "Load validation files, apply validation transforms and display (no inverses yet!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "to_imshow = []\n",
    "\n",
    "for file in np.random.choice(val_files, size=5, replace=False):\n",
    "    data = val_transforms(file)\n",
    "    inferred = post_trans(model(data[\"image\"][None].to(device))[0])\n",
    "    to_imshow.append({\n",
    "        \"image\": data[\"image\"],\n",
    "        \"GT label\": data[\"label\"],\n",
    "        \"inferred label\": inferred,\n",
    "    })\n",
    "imshows(to_imshow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.visualize.utils import blend_images\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transforms = mt.Compose([\n",
    "        mt.LoadImaged(keys),\n",
    "        mt.Rotate90d(keys),\n",
    "        mt.CropForegroundd(keys, source_key=\"image\", margin=5),\n",
    "])\n",
    "\n",
    "idx = 0\n",
    "data = train_files[idx]\n",
    "data = transforms(data)\n",
    "img, lbl = data[\"image\"][:1], data[\"label\"]\n",
    "\n",
    "blended = np.moveaxis(blend_images(img, lbl), 0, -1)\n",
    "\n",
    "plt.figure(figsize=(100, 100))\n",
    "plt.imshow(blended)\n",
    "_ = plt.axis(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
